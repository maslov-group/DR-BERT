{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d0e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizerFast, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, log_loss, accuracy_score, matthews_corrcoef\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8058986",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 1024\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-6\n",
    "BATCH_SIZE = 1\n",
    "TOKENIZER_PATH =  \"./Models/ST-PRoBERTa/Tokenizer\"\n",
    "PRETRAINED_MODEL = \"./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000\"\n",
    "NUM_CLASSES = 2\n",
    "SCHEDULER='cosine_with_restarts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5635e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pickle.load(open('./Datasets/finetuning-IDRs-train.pickle', \"rb\"))\n",
    "df_test = pickle.load(open('./Datasets/finetuning-IDRs-test.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83bf0061",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8963357b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>full</th>\n",
       "      <th>disprot_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MELITNELLYKTYKQKPVGVEEPVYDQAGDPLFGERGAVHPQSTLK...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP00675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESAQAVAEPLDLVRLSLDEIVYVKLRGDRELNGRLHAYDEHLNMV...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP02065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MPYLKGAPMNLQEMEKNSAKAVVLLKAMANERRLQILCMLLDNELS...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>DP02188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAEKPKLHYFNARGRMESTRWLLAAAGVEFEEKFIKSAEDLDKLRN...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP01506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAGVGTPCANGCGPSAPSEAEVLHLCRSLEVGTVMTLFYSKKSQRP...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP01851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>MLALLCSCLLLAAGASDAWTGEDSAEPNSDSAEWIRDMYAKVTEIW...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP02656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>MGEAEKFHYIYSCDLDINVQLKIGSLEGKREQKSYKAVLEDPMLKF...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP03710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>MASMRESDTGLWLHNKLGATDELWAPPSIASLLTAAVIDNIRLCFH...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP02712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>MLSTQFNRDNQYQAITKPSLLAGCIALALLPSAAFAAPATEETVIV...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP03193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>MTGLYELVWRVLHALLCLHLTLTSWLRVRFGTWNWIWRRCCRAASA...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP01304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2386 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sequence  \\\n",
       "0    MELITNELLYKTYKQKPVGVEEPVYDQAGDPLFGERGAVHPQSTLK...   \n",
       "1    MESAQAVAEPLDLVRLSLDEIVYVKLRGDRELNGRLHAYDEHLNMV...   \n",
       "2    MPYLKGAPMNLQEMEKNSAKAVVLLKAMANERRLQILCMLLDNELS...   \n",
       "3    MAEKPKLHYFNARGRMESTRWLLAAAGVEFEEKFIKSAEDLDKLRN...   \n",
       "4    MAGVGTPCANGCGPSAPSEAEVLHLCRSLEVGTVMTLFYSKKSQRP...   \n",
       "..                                                 ...   \n",
       "235  MLALLCSCLLLAAGASDAWTGEDSAEPNSDSAEWIRDMYAKVTEIW...   \n",
       "236  MGEAEKFHYIYSCDLDINVQLKIGSLEGKREQKSYKAVLEDPMLKF...   \n",
       "237  MASMRESDTGLWLHNKLGATDELWAPPSIASLLTAAVIDNIRLCFH...   \n",
       "238  MLSTQFNRDNQYQAITKPSLLAGCIALALLPSAAFAAPATEETVIV...   \n",
       "239  MTGLYELVWRVLHALLCLHLTLTSWLRVRFGTWNWIWRRCCRAASA...   \n",
       "\n",
       "                                                  full disprot_ID  \n",
       "0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00675  \n",
       "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02065  \n",
       "2    [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...    DP02188  \n",
       "3    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP01506  \n",
       "4    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP01851  \n",
       "..                                                 ...        ...  \n",
       "235  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02656  \n",
       "236  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP03710  \n",
       "237  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02712  \n",
       "238  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP03193  \n",
       "239  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP01304  \n",
       "\n",
       "[2386 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e8f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caid = pickle.load(open('./Datasets/caid.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fe6f82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DP00084</td>\n",
       "      <td>MSDNDDIEVESDEEQPRFQSAADKRAHHNALERKRRDHIKDSFHSL...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DP00182</td>\n",
       "      <td>MAPTKRKGSCPGAAPKKPKEPVQVPKLVIKGGIEVLGVKTGVDSFT...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DP00206</td>\n",
       "      <td>MKAAQKGFTLIELMIVVAIIGILAAIAIPAYQDYTARAQLSERMTL...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DP00334</td>\n",
       "      <td>MCNTNMSVPTDGAVTTSQIPASEQETLVRPKPLLLKLLKSVGAQKD...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DP00359</td>\n",
       "      <td>MMLTKSVVISRPAVRPVSTRRAVVVRASGQPAVDLNKKVQDAVKEA...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>DP02330</td>\n",
       "      <td>MWLPLTVLLLAGIVSADYDHGWHVNNEYIYLVRSRTLVNLNELSDQ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>DP02331</td>\n",
       "      <td>MWCPLFLVLLAGAATAEHLQAWKTDTEYQYAVRGRTLSALHDVADQ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>DP02332</td>\n",
       "      <td>MAGELADKKDRDASPSKEERKRSRTPDRERDRDRDRKSSPSKDRKR...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>DP02333</td>\n",
       "      <td>MSHIQIPPGLTELLQGYTVEVLRQQPPDLVEFAVEYFTRLREARAP...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>DP02334</td>\n",
       "      <td>MAPPGMRLRSGRSTGAPLTRGSCRKRNRSPERCDLGDDLHLQPRRK...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>652 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                           Sequence  \\\n",
       "0    DP00084  MSDNDDIEVESDEEQPRFQSAADKRAHHNALERKRRDHIKDSFHSL...   \n",
       "1    DP00182  MAPTKRKGSCPGAAPKKPKEPVQVPKLVIKGGIEVLGVKTGVDSFT...   \n",
       "2    DP00206  MKAAQKGFTLIELMIVVAIIGILAAIAIPAYQDYTARAQLSERMTL...   \n",
       "3    DP00334  MCNTNMSVPTDGAVTTSQIPASEQETLVRPKPLLLKLLKSVGAQKD...   \n",
       "4    DP00359  MMLTKSVVISRPAVRPVSTRRAVVVRASGQPAVDLNKKVQDAVKEA...   \n",
       "..       ...                                                ...   \n",
       "647  DP02330  MWLPLTVLLLAGIVSADYDHGWHVNNEYIYLVRSRTLVNLNELSDQ...   \n",
       "648  DP02331  MWCPLFLVLLAGAATAEHLQAWKTDTEYQYAVRGRTLSALHDVADQ...   \n",
       "649  DP02332  MAGELADKKDRDASPSKEERKRSRTPDRERDRDRDRKSSPSKDRKR...   \n",
       "650  DP02333  MSHIQIPPGLTELLQGYTVEVLRQQPPDLVEFAVEYFTRLREARAP...   \n",
       "651  DP02334  MAPPGMRLRSGRSTGAPLTRGSCRKRNRSPERCDLGDDLHLQPRRK...   \n",
       "\n",
       "                                                  full  \n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "..                                                 ...  \n",
       "647  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "648  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "649  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "650  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "651  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[652 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_caid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e2ab4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>full</th>\n",
       "      <th>disprot_ID</th>\n",
       "      <th>intersect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MELITNELLYKTYKQKPVGVEEPVYDQAGDPLFGERGAVHPQSTLK...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP00675</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MEDINFASLAPRHGSRPFMGNWQDIGTSNMSGGAFSWGSLWSGIKN...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP00808</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MVSSVLSIPPQTCLLPRLPISDSVNCKSKIVYCLSTSVRGSSVKRQ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP02919</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MAAKFEVGSVYTGKVTGLQAYGAFVALDEETQGLVHISEVTHGFVK...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP00809</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VVYTDCTESGQNLCLCEGSNVCGQGNKCILGSDGEKNQCVTGEGTP...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP00137</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>MGHNDSVETMDEISNPNNILLPHDGTGLDATGISGSQEPYGMVDVL...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>DP00036</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>MLALLCSCLLLAAGASDAWTGEDSAEPNSDSAEWIRDMYAKVTEIW...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP02656</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>MGEAEKFHYIYSCDLDINVQLKIGSLEGKREQKSYKAVLEDPMLKF...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP03710</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>MASMRESDTGLWLHNKLGATDELWAPPSIASLLTAAVIDNIRLCFH...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP02712</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>MLSTQFNRDNQYQAITKPSLLAGCIALALLPSAAFAAPATEETVIV...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP03193</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1760 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sequence  \\\n",
       "0    MELITNELLYKTYKQKPVGVEEPVYDQAGDPLFGERGAVHPQSTLK...   \n",
       "5    MEDINFASLAPRHGSRPFMGNWQDIGTSNMSGGAFSWGSLWSGIKN...   \n",
       "6    MVSSVLSIPPQTCLLPRLPISDSVNCKSKIVYCLSTSVRGSSVKRQ...   \n",
       "7    MAAKFEVGSVYTGKVTGLQAYGAFVALDEETQGLVHISEVTHGFVK...   \n",
       "9    VVYTDCTESGQNLCLCEGSNVCGQGNKCILGSDGEKNQCVTGEGTP...   \n",
       "..                                                 ...   \n",
       "234  MGHNDSVETMDEISNPNNILLPHDGTGLDATGISGSQEPYGMVDVL...   \n",
       "235  MLALLCSCLLLAAGASDAWTGEDSAEPNSDSAEWIRDMYAKVTEIW...   \n",
       "236  MGEAEKFHYIYSCDLDINVQLKIGSLEGKREQKSYKAVLEDPMLKF...   \n",
       "237  MASMRESDTGLWLHNKLGATDELWAPPSIASLLTAAVIDNIRLCFH...   \n",
       "238  MLSTQFNRDNQYQAITKPSLLAGCIALALLPSAAFAAPATEETVIV...   \n",
       "\n",
       "                                                  full disprot_ID  intersect  \n",
       "0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00675      False  \n",
       "5    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00808      False  \n",
       "6    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02919      False  \n",
       "7    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00809      False  \n",
       "9    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00137      False  \n",
       "..                                                 ...        ...        ...  \n",
       "234  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...    DP00036      False  \n",
       "235  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02656      False  \n",
       "236  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP03710      False  \n",
       "237  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02712      False  \n",
       "238  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP03193      False  \n",
       "\n",
       "[1760 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train = df_full[~df_full['disprot_ID'].isin(df_caid['ID'])]\n",
    "df_full['intersect'] = [i in list(df_caid['ID']) for i in df_full['disprot_ID']]\n",
    "df_train = df_full[df_full['intersect'] == False]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09e3d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['full'] = [[int(i) for i in j] for j in df_train['full']]\n",
    "# df_caid['full'] = [[int(i) for i in j] for j in df_caid['full']]\n",
    "# print(df_train), print(df_caid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a46fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['disordered_content'] = [list(i).count(1)/len(i) for i in df_train['full']]\n",
    "# df_caid['disordered_content'] = [list(i).count(1)/len(i) for i in df_caid['full']]\n",
    "# df_train.hist('disordered_content')\n",
    "# df_caid.hist('disordered_content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10e5ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train[df_train['disordered_content'] < 0.9]\n",
    "# df_train.hist('disordered_content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76cb2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_train.sample(frac=0.1)\n",
    "df_train = df_train.drop(df_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0e4149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.to_pickle('val.pkl')\n",
    "df_train.to_pickle('train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35c1389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_caid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1806d860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          ID                                           Sequence  \\\n",
       " 0    DP00084  MSDNDDIEVESDEEQPRFQSAADKRAHHNALERKRRDHIKDSFHSL...   \n",
       " 1    DP00182  MAPTKRKGSCPGAAPKKPKEPVQVPKLVIKGGIEVLGVKTGVDSFT...   \n",
       " 2    DP00206  MKAAQKGFTLIELMIVVAIIGILAAIAIPAYQDYTARAQLSERMTL...   \n",
       " 3    DP00334  MCNTNMSVPTDGAVTTSQIPASEQETLVRPKPLLLKLLKSVGAQKD...   \n",
       " 4    DP00359  MMLTKSVVISRPAVRPVSTRRAVVVRASGQPAVDLNKKVQDAVKEA...   \n",
       " ..       ...                                                ...   \n",
       " 647  DP02330  MWLPLTVLLLAGIVSADYDHGWHVNNEYIYLVRSRTLVNLNELSDQ...   \n",
       " 648  DP02331  MWCPLFLVLLAGAATAEHLQAWKTDTEYQYAVRGRTLSALHDVADQ...   \n",
       " 649  DP02332  MAGELADKKDRDASPSKEERKRSRTPDRERDRDRDRKSSPSKDRKR...   \n",
       " 650  DP02333  MSHIQIPPGLTELLQGYTVEVLRQQPPDLVEFAVEYFTRLREARAP...   \n",
       " 651  DP02334  MAPPGMRLRSGRSTGAPLTRGSCRKRNRSPERCDLGDDLHLQPRRK...   \n",
       " \n",
       "                                                   full  \n",
       " 0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " 1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       " 2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " 3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " 4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " ..                                                 ...  \n",
       " 647  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " 648  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " 649  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       " 650  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " 651  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " \n",
       " [652 rows x 3 columns],\n",
       "                                               Sequence  \\\n",
       " 0    MELITNELLYKTYKQKPVGVEEPVYDQAGDPLFGERGAVHPQSTLK...   \n",
       " 5    MEDINFASLAPRHGSRPFMGNWQDIGTSNMSGGAFSWGSLWSGIKN...   \n",
       " 7    MAAKFEVGSVYTGKVTGLQAYGAFVALDEETQGLVHISEVTHGFVK...   \n",
       " 9    VVYTDCTESGQNLCLCEGSNVCGQGNKCILGSDGEKNQCVTGEGTP...   \n",
       " 11   MNYIPTQTFYGRRWRPRPAARPWPLQATPVAPVVPDFQAQQMQQLI...   \n",
       " ..                                                 ...   \n",
       " 232  MITKVDRNAVRKKRHARIRKKIFGTTERPRLSVFRSNKHIYAQIID...   \n",
       " 234  MGHNDSVETMDEISNPNNILLPHDGTGLDATGISGSQEPYGMVDVL...   \n",
       " 235  MLALLCSCLLLAAGASDAWTGEDSAEPNSDSAEWIRDMYAKVTEIW...   \n",
       " 236  MGEAEKFHYIYSCDLDINVQLKIGSLEGKREQKSYKAVLEDPMLKF...   \n",
       " 238  MLSTQFNRDNQYQAITKPSLLAGCIALALLPSAAFAAPATEETVIV...   \n",
       " \n",
       "                                                   full disprot_ID  intersect  \n",
       " 0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00675      False  \n",
       " 5    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00808      False  \n",
       " 7    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00809      False  \n",
       " 9    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00137      False  \n",
       " 11   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00999      False  \n",
       " ..                                                 ...        ...        ...  \n",
       " 232  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...    DP00966      False  \n",
       " 234  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...    DP00036      False  \n",
       " 235  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02656      False  \n",
       " 236  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP03710      False  \n",
       " 238  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP03193      False  \n",
       " \n",
       " [1569 rows x 4 columns],\n",
       "                                                Sequence  \\\n",
       " 1823  MIPVTILCVLLCLNLAWAQDGKTTFEKEGGGGRGPRILENMHESSC...   \n",
       " 1283  MGNLESTDGGPGEPPSVPLLLPPGKTPMPEPCELEERFALVLSSMN...   \n",
       " 1868  MSGSVSGCGSGGCSIVWFRRDLRVEDNPALAAAVRAGPVIALFVWA...   \n",
       " 1416  MATVNQLVRKPRARKVAKSNVPALEACPQKRGVCTRVYTTTPKKPN...   \n",
       " 170   MAQWEMLQNLDSPFQDQLHQLYSHSLLPVDIRQYLAVWIEDQNWQE...   \n",
       " ...                                                 ...   \n",
       " 1154  MFGCLVAGRLVQTAAQQVAEDKFVFDLPDYESINHVVVFMLGTIPF...   \n",
       " 1446  MKYRYFAKKSFLFISMLAAFKTFAFELPSVPFPAPGSDEILFVVRD...   \n",
       " 2033  MQVEANSERRVKILGIDRSENSPVLTYMETEDDPNFRNSKLAAAPH...   \n",
       " 950   MLNRENKTAITRKGMVSNRLNKFSIRKYTVGTASILVGTTLIFGLG...   \n",
       " 1762  MKTLADALKEFEVLSFEIDEQALAFDVDNIEMVIEKSDITPVPKSR...   \n",
       " \n",
       "                                                    full disprot_ID  intersect  \n",
       " 1823  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00233      False  \n",
       " 1283  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02638      False  \n",
       " 1868  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...    DP00474      False  \n",
       " 1416  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...    DP00145      False  \n",
       " 170   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00961      False  \n",
       " ...                                                 ...        ...        ...  \n",
       " 1154  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02719      False  \n",
       " 1446  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00668      False  \n",
       " 2033  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP03107      False  \n",
       " 950   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00065      False  \n",
       " 1762  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00350      False  \n",
       " \n",
       " [176 rows x 4 columns])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test, df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0a7edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDegreeDataset(Dataset):\n",
    "\n",
    "    def __init__(self, max_length, df, tokenizer, region_type):\n",
    "        self.region_type = region_type\n",
    "        self.df = df\n",
    "        self.seqs, self.labels = self.load_dataset()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def load_dataset(self):\n",
    "        seq = list(self.df['Sequence'])\n",
    "        label = list(self.df[self.region_type])\n",
    "        return seq, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        seq = \" \".join(\"\".join(self.seqs[idx].split()))\n",
    "        seq = re.sub(r\"[UZOB]\", \"X\", seq)\n",
    "\n",
    "        seq_ids = self.tokenizer(seq, truncation=True, padding='max_length', max_length=self.max_length)\n",
    "        sample = {key: torch.tensor(val) for key, val in seq_ids.items()}\n",
    "        tens = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        sample['labels'] = F.pad(tens, (0, MAX_LENGTH - len(tens)))\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b6911f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file ./Models/ST-PRoBERTa/Tokenizer/config.json not found\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "file ./Models/ST-PRoBERTa/Tokenizer/config.json not found\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(TOKENIZER_PATH, do_lower_case=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10fc1436",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ProteinDegreeDataset(MAX_LENGTH, df_train, tokenizer, 'full')\n",
    "val_dataset = ProteinDegreeDataset(MAX_LENGTH, df_val, tokenizer, 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e39540f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = f'./Models/DR-BERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdf4a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0009a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_f1_roc_convolve(name, logits, labels, convolution):\n",
    "    convolved = np.convolve(np.array(logits).flatten(), np.array(convolution / np.sum(convolution)).flatten(), 'same')\n",
    "    p = [(1 - i, i) for i in convolved]\n",
    "    roc = [i[1] for i in p]\n",
    "    roc2 = [i[0] for i in p]\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(labels, p)\n",
    "    roc_auc = roc_auc_score(labels, roc)\n",
    "    mcc = matthews_corrcoef(labels, p)\n",
    "    return {\n",
    "        f'precision_{name}':precision[1],\n",
    "        f'recall_{name}':recall[1],\n",
    "        f'f1_{name}':f1[1],\n",
    "        f'roc_auc_{name}':roc_auc,\n",
    "        f'mcc_{name}': mcc,\n",
    "    }\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    logits = softmax(logits, axis=2)\n",
    "    l = []\n",
    "    for j, i in enumerate(labels):\n",
    "        l = l + list(i[:len(df_val['Sequence'].iloc[j])])\n",
    "    lg2 = []\n",
    "    for k, i in enumerate(logits):\n",
    "        lg2 = lg2 + [j[1] for j in i[:len(df_val['Sequence'].iloc[k])]]\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics.update(precision_recall_f1_roc_convolve('normal', lg2, l, [1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('wa5', lg2, l, [1,1,1,1,1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('wa9', lg2, l, [1,1,1,1,1,1,1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('wa15', lg2, l, [1]*15))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('linear5', lg2, l, [1,2,3,2,1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('linear9', lg2, l, [1,2,3,4,5,4,3,2,1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('linear15', lg2, l, [1,2,3,4,5,6,7,8,7,6,5,4,3,2,1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('quad5', lg2, l, [1,3,9,3,1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('quad9', lg2, l, [1,3,9,27,81,27,9,3,1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('quad15', lg2, l, [1,3,9,27,81,243,729,2187,729,243,81,27,9,3,1]))\n",
    "    \n",
    "    logits_path = OUTPUT_DIR + '/Logits/'\n",
    "    if not os.path.isdir(logits_path):\n",
    "        os.mkdir(logits_path)\n",
    "    new_df = deepcopy(df_val)\n",
    "    new_df['Logits'] = [[i[1] for i in x] for x in list(logits)]\n",
    "    pickle.dump(new_df, open(logits_path + datetime.now().strftime(\"%H:%M:%S\"), 'wb'))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "882d3738",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = OUTPUT_DIR + '/Checkpoints',\n",
    "    num_train_epochs = EPOCHS,\n",
    "    per_device_train_batch_size = 1,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    warmup_steps = 1000,\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    logging_dir = OUTPUT_DIR + '/Logs',\n",
    "    logging_steps = 200,\n",
    "    lr_scheduler_type=SCHEDULER,\n",
    "    do_train = True,\n",
    "    do_eval = True,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    gradient_accumulation_steps = BATCH_SIZE,\n",
    "    fp16 = True,\n",
    "    fp16_opt_level = '02',\n",
    "    save_strategy = 'epoch',\n",
    "    load_best_model_at_end = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5d3121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "def model_init():\n",
    "    model = AutoModelForTokenClassification.from_pretrained(PRETRAINED_MODEL, num_labels=NUM_CLASSES)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27db5718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 35\n",
      "}\n",
      "\n",
      "loading weights file ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000/pytorch_model.bin\n",
      "Some weights of the model checkpoint at ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000 were not used when initializing RobertaForTokenClassification: ['lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = val_dataset,\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3af3900e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 35\n",
      "}\n",
      "\n",
      "loading weights file ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000/pytorch_model.bin\n",
      "Some weights of the model checkpoint at ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000 were not used when initializing RobertaForTokenClassification: ['lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/johnmf4/.conda/envs/ProteinTransformers3/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1569\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15690\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15690' max='15690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15690/15690 18:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision Normal</th>\n",
       "      <th>Recall Normal</th>\n",
       "      <th>F1 Normal</th>\n",
       "      <th>Roc Auc Normal</th>\n",
       "      <th>Mcc Normal</th>\n",
       "      <th>Precision Wa5</th>\n",
       "      <th>Recall Wa5</th>\n",
       "      <th>F1 Wa5</th>\n",
       "      <th>Roc Auc Wa5</th>\n",
       "      <th>Mcc Wa5</th>\n",
       "      <th>Precision Wa9</th>\n",
       "      <th>Recall Wa9</th>\n",
       "      <th>F1 Wa9</th>\n",
       "      <th>Roc Auc Wa9</th>\n",
       "      <th>Mcc Wa9</th>\n",
       "      <th>Precision Wa15</th>\n",
       "      <th>Recall Wa15</th>\n",
       "      <th>F1 Wa15</th>\n",
       "      <th>Roc Auc Wa15</th>\n",
       "      <th>Mcc Wa15</th>\n",
       "      <th>Precision Linear5</th>\n",
       "      <th>Recall Linear5</th>\n",
       "      <th>F1 Linear5</th>\n",
       "      <th>Roc Auc Linear5</th>\n",
       "      <th>Mcc Linear5</th>\n",
       "      <th>Precision Linear9</th>\n",
       "      <th>Recall Linear9</th>\n",
       "      <th>F1 Linear9</th>\n",
       "      <th>Roc Auc Linear9</th>\n",
       "      <th>Mcc Linear9</th>\n",
       "      <th>Precision Linear15</th>\n",
       "      <th>Recall Linear15</th>\n",
       "      <th>F1 Linear15</th>\n",
       "      <th>Roc Auc Linear15</th>\n",
       "      <th>Mcc Linear15</th>\n",
       "      <th>Precision Quad5</th>\n",
       "      <th>Recall Quad5</th>\n",
       "      <th>F1 Quad5</th>\n",
       "      <th>Roc Auc Quad5</th>\n",
       "      <th>Mcc Quad5</th>\n",
       "      <th>Precision Quad9</th>\n",
       "      <th>Recall Quad9</th>\n",
       "      <th>F1 Quad9</th>\n",
       "      <th>Roc Auc Quad9</th>\n",
       "      <th>Mcc Quad9</th>\n",
       "      <th>Precision Quad15</th>\n",
       "      <th>Recall Quad15</th>\n",
       "      <th>F1 Quad15</th>\n",
       "      <th>Roc Auc Quad15</th>\n",
       "      <th>Mcc Quad15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.545600</td>\n",
       "      <td>0.422219</td>\n",
       "      <td>0.855556</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.009390</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.055004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.781875</td>\n",
       "      <td>0.051830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.782284</td>\n",
       "      <td>0.051830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.782848</td>\n",
       "      <td>0.047835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>0.006722</td>\n",
       "      <td>0.781734</td>\n",
       "      <td>0.052308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>0.006478</td>\n",
       "      <td>0.782423</td>\n",
       "      <td>0.051348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.782839</td>\n",
       "      <td>0.049371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>0.780894</td>\n",
       "      <td>0.055089</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.007209</td>\n",
       "      <td>0.781147</td>\n",
       "      <td>0.054178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.007209</td>\n",
       "      <td>0.781180</td>\n",
       "      <td>0.054178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.487400</td>\n",
       "      <td>0.405703</td>\n",
       "      <td>0.587768</td>\n",
       "      <td>0.285776</td>\n",
       "      <td>0.384571</td>\n",
       "      <td>0.804499</td>\n",
       "      <td>0.323937</td>\n",
       "      <td>0.593356</td>\n",
       "      <td>0.282526</td>\n",
       "      <td>0.382788</td>\n",
       "      <td>0.806676</td>\n",
       "      <td>0.324724</td>\n",
       "      <td>0.595819</td>\n",
       "      <td>0.281361</td>\n",
       "      <td>0.382226</td>\n",
       "      <td>0.806957</td>\n",
       "      <td>0.325221</td>\n",
       "      <td>0.602387</td>\n",
       "      <td>0.272348</td>\n",
       "      <td>0.375106</td>\n",
       "      <td>0.807812</td>\n",
       "      <td>0.322686</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.284243</td>\n",
       "      <td>0.384427</td>\n",
       "      <td>0.806633</td>\n",
       "      <td>0.325967</td>\n",
       "      <td>0.596653</td>\n",
       "      <td>0.281974</td>\n",
       "      <td>0.382963</td>\n",
       "      <td>0.807059</td>\n",
       "      <td>0.326027</td>\n",
       "      <td>0.599334</td>\n",
       "      <td>0.275966</td>\n",
       "      <td>0.377918</td>\n",
       "      <td>0.807609</td>\n",
       "      <td>0.323522</td>\n",
       "      <td>0.593093</td>\n",
       "      <td>0.285346</td>\n",
       "      <td>0.385313</td>\n",
       "      <td>0.806361</td>\n",
       "      <td>0.326369</td>\n",
       "      <td>0.593798</td>\n",
       "      <td>0.285285</td>\n",
       "      <td>0.385405</td>\n",
       "      <td>0.806506</td>\n",
       "      <td>0.326686</td>\n",
       "      <td>0.593738</td>\n",
       "      <td>0.284856</td>\n",
       "      <td>0.385001</td>\n",
       "      <td>0.806538</td>\n",
       "      <td>0.326386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.453100</td>\n",
       "      <td>0.429115</td>\n",
       "      <td>0.606127</td>\n",
       "      <td>0.254752</td>\n",
       "      <td>0.358731</td>\n",
       "      <td>0.803214</td>\n",
       "      <td>0.312911</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.248927</td>\n",
       "      <td>0.353351</td>\n",
       "      <td>0.804995</td>\n",
       "      <td>0.310200</td>\n",
       "      <td>0.609335</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.351041</td>\n",
       "      <td>0.805222</td>\n",
       "      <td>0.308877</td>\n",
       "      <td>0.613640</td>\n",
       "      <td>0.240527</td>\n",
       "      <td>0.345593</td>\n",
       "      <td>0.805768</td>\n",
       "      <td>0.306736</td>\n",
       "      <td>0.609683</td>\n",
       "      <td>0.250153</td>\n",
       "      <td>0.354752</td>\n",
       "      <td>0.804973</td>\n",
       "      <td>0.311486</td>\n",
       "      <td>0.609209</td>\n",
       "      <td>0.246597</td>\n",
       "      <td>0.351082</td>\n",
       "      <td>0.805317</td>\n",
       "      <td>0.308861</td>\n",
       "      <td>0.612749</td>\n",
       "      <td>0.243409</td>\n",
       "      <td>0.348414</td>\n",
       "      <td>0.805725</td>\n",
       "      <td>0.308310</td>\n",
       "      <td>0.608226</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.356409</td>\n",
       "      <td>0.804743</td>\n",
       "      <td>0.312088</td>\n",
       "      <td>0.608876</td>\n",
       "      <td>0.251502</td>\n",
       "      <td>0.355968</td>\n",
       "      <td>0.804865</td>\n",
       "      <td>0.312020</td>\n",
       "      <td>0.609090</td>\n",
       "      <td>0.251441</td>\n",
       "      <td>0.355943</td>\n",
       "      <td>0.804895</td>\n",
       "      <td>0.312078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.420400</td>\n",
       "      <td>0.416325</td>\n",
       "      <td>0.579619</td>\n",
       "      <td>0.287002</td>\n",
       "      <td>0.383909</td>\n",
       "      <td>0.804223</td>\n",
       "      <td>0.320522</td>\n",
       "      <td>0.581777</td>\n",
       "      <td>0.282649</td>\n",
       "      <td>0.380457</td>\n",
       "      <td>0.805678</td>\n",
       "      <td>0.318936</td>\n",
       "      <td>0.583302</td>\n",
       "      <td>0.282281</td>\n",
       "      <td>0.380449</td>\n",
       "      <td>0.805875</td>\n",
       "      <td>0.319484</td>\n",
       "      <td>0.585251</td>\n",
       "      <td>0.274433</td>\n",
       "      <td>0.373654</td>\n",
       "      <td>0.806462</td>\n",
       "      <td>0.315549</td>\n",
       "      <td>0.582495</td>\n",
       "      <td>0.283998</td>\n",
       "      <td>0.381832</td>\n",
       "      <td>0.805673</td>\n",
       "      <td>0.320140</td>\n",
       "      <td>0.583164</td>\n",
       "      <td>0.282036</td>\n",
       "      <td>0.380197</td>\n",
       "      <td>0.805964</td>\n",
       "      <td>0.319262</td>\n",
       "      <td>0.583623</td>\n",
       "      <td>0.277928</td>\n",
       "      <td>0.376542</td>\n",
       "      <td>0.806375</td>\n",
       "      <td>0.316928</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.285224</td>\n",
       "      <td>0.382550</td>\n",
       "      <td>0.805502</td>\n",
       "      <td>0.319981</td>\n",
       "      <td>0.581404</td>\n",
       "      <td>0.284856</td>\n",
       "      <td>0.382371</td>\n",
       "      <td>0.805604</td>\n",
       "      <td>0.320114</td>\n",
       "      <td>0.581069</td>\n",
       "      <td>0.284549</td>\n",
       "      <td>0.382022</td>\n",
       "      <td>0.805632</td>\n",
       "      <td>0.319753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.468300</td>\n",
       "      <td>0.413421</td>\n",
       "      <td>0.548662</td>\n",
       "      <td>0.328020</td>\n",
       "      <td>0.410575</td>\n",
       "      <td>0.804822</td>\n",
       "      <td>0.327806</td>\n",
       "      <td>0.548491</td>\n",
       "      <td>0.324218</td>\n",
       "      <td>0.407537</td>\n",
       "      <td>0.806166</td>\n",
       "      <td>0.325563</td>\n",
       "      <td>0.549514</td>\n",
       "      <td>0.322195</td>\n",
       "      <td>0.406215</td>\n",
       "      <td>0.806364</td>\n",
       "      <td>0.325001</td>\n",
       "      <td>0.549421</td>\n",
       "      <td>0.314224</td>\n",
       "      <td>0.399797</td>\n",
       "      <td>0.806975</td>\n",
       "      <td>0.320409</td>\n",
       "      <td>0.548888</td>\n",
       "      <td>0.325261</td>\n",
       "      <td>0.408470</td>\n",
       "      <td>0.806170</td>\n",
       "      <td>0.326379</td>\n",
       "      <td>0.549227</td>\n",
       "      <td>0.322195</td>\n",
       "      <td>0.406136</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.324837</td>\n",
       "      <td>0.550476</td>\n",
       "      <td>0.318945</td>\n",
       "      <td>0.403882</td>\n",
       "      <td>0.806875</td>\n",
       "      <td>0.323699</td>\n",
       "      <td>0.549092</td>\n",
       "      <td>0.326426</td>\n",
       "      <td>0.409444</td>\n",
       "      <td>0.806013</td>\n",
       "      <td>0.327154</td>\n",
       "      <td>0.549184</td>\n",
       "      <td>0.325874</td>\n",
       "      <td>0.409035</td>\n",
       "      <td>0.806111</td>\n",
       "      <td>0.326895</td>\n",
       "      <td>0.549064</td>\n",
       "      <td>0.325567</td>\n",
       "      <td>0.408760</td>\n",
       "      <td>0.806138</td>\n",
       "      <td>0.326653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.465700</td>\n",
       "      <td>0.424295</td>\n",
       "      <td>0.554089</td>\n",
       "      <td>0.316554</td>\n",
       "      <td>0.402919</td>\n",
       "      <td>0.804076</td>\n",
       "      <td>0.324365</td>\n",
       "      <td>0.553028</td>\n",
       "      <td>0.312998</td>\n",
       "      <td>0.399749</td>\n",
       "      <td>0.805333</td>\n",
       "      <td>0.321727</td>\n",
       "      <td>0.553391</td>\n",
       "      <td>0.311711</td>\n",
       "      <td>0.398792</td>\n",
       "      <td>0.805496</td>\n",
       "      <td>0.321188</td>\n",
       "      <td>0.554626</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.393336</td>\n",
       "      <td>0.805905</td>\n",
       "      <td>0.317822</td>\n",
       "      <td>0.553674</td>\n",
       "      <td>0.314654</td>\n",
       "      <td>0.401267</td>\n",
       "      <td>0.805348</td>\n",
       "      <td>0.323040</td>\n",
       "      <td>0.553791</td>\n",
       "      <td>0.312140</td>\n",
       "      <td>0.399247</td>\n",
       "      <td>0.805581</td>\n",
       "      <td>0.321658</td>\n",
       "      <td>0.555433</td>\n",
       "      <td>0.309319</td>\n",
       "      <td>0.397354</td>\n",
       "      <td>0.805910</td>\n",
       "      <td>0.320939</td>\n",
       "      <td>0.553916</td>\n",
       "      <td>0.315267</td>\n",
       "      <td>0.401829</td>\n",
       "      <td>0.805206</td>\n",
       "      <td>0.323528</td>\n",
       "      <td>0.554009</td>\n",
       "      <td>0.314776</td>\n",
       "      <td>0.401454</td>\n",
       "      <td>0.805291</td>\n",
       "      <td>0.323298</td>\n",
       "      <td>0.554223</td>\n",
       "      <td>0.314592</td>\n",
       "      <td>0.401361</td>\n",
       "      <td>0.805318</td>\n",
       "      <td>0.323312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.440800</td>\n",
       "      <td>0.421556</td>\n",
       "      <td>0.546304</td>\n",
       "      <td>0.329859</td>\n",
       "      <td>0.411346</td>\n",
       "      <td>0.803581</td>\n",
       "      <td>0.327480</td>\n",
       "      <td>0.549809</td>\n",
       "      <td>0.327223</td>\n",
       "      <td>0.410270</td>\n",
       "      <td>0.804817</td>\n",
       "      <td>0.328015</td>\n",
       "      <td>0.549405</td>\n",
       "      <td>0.325567</td>\n",
       "      <td>0.408855</td>\n",
       "      <td>0.804974</td>\n",
       "      <td>0.326848</td>\n",
       "      <td>0.551285</td>\n",
       "      <td>0.318332</td>\n",
       "      <td>0.403607</td>\n",
       "      <td>0.805387</td>\n",
       "      <td>0.323806</td>\n",
       "      <td>0.549491</td>\n",
       "      <td>0.327774</td>\n",
       "      <td>0.410615</td>\n",
       "      <td>0.804835</td>\n",
       "      <td>0.328144</td>\n",
       "      <td>0.550181</td>\n",
       "      <td>0.325690</td>\n",
       "      <td>0.409166</td>\n",
       "      <td>0.805064</td>\n",
       "      <td>0.327362</td>\n",
       "      <td>0.551160</td>\n",
       "      <td>0.322011</td>\n",
       "      <td>0.406517</td>\n",
       "      <td>0.805393</td>\n",
       "      <td>0.325832</td>\n",
       "      <td>0.548779</td>\n",
       "      <td>0.329368</td>\n",
       "      <td>0.411663</td>\n",
       "      <td>0.804695</td>\n",
       "      <td>0.328633</td>\n",
       "      <td>0.548853</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0.411061</td>\n",
       "      <td>0.804781</td>\n",
       "      <td>0.328227</td>\n",
       "      <td>0.548807</td>\n",
       "      <td>0.328510</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.804808</td>\n",
       "      <td>0.328166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.425100</td>\n",
       "      <td>0.426329</td>\n",
       "      <td>0.560408</td>\n",
       "      <td>0.309994</td>\n",
       "      <td>0.399179</td>\n",
       "      <td>0.802881</td>\n",
       "      <td>0.324075</td>\n",
       "      <td>0.560721</td>\n",
       "      <td>0.306867</td>\n",
       "      <td>0.396656</td>\n",
       "      <td>0.804105</td>\n",
       "      <td>0.322418</td>\n",
       "      <td>0.560449</td>\n",
       "      <td>0.305825</td>\n",
       "      <td>0.395716</td>\n",
       "      <td>0.804246</td>\n",
       "      <td>0.321658</td>\n",
       "      <td>0.561373</td>\n",
       "      <td>0.299755</td>\n",
       "      <td>0.390823</td>\n",
       "      <td>0.804564</td>\n",
       "      <td>0.318587</td>\n",
       "      <td>0.560965</td>\n",
       "      <td>0.308032</td>\n",
       "      <td>0.397689</td>\n",
       "      <td>0.804122</td>\n",
       "      <td>0.323234</td>\n",
       "      <td>0.560764</td>\n",
       "      <td>0.305825</td>\n",
       "      <td>0.395794</td>\n",
       "      <td>0.804331</td>\n",
       "      <td>0.321831</td>\n",
       "      <td>0.560740</td>\n",
       "      <td>0.302820</td>\n",
       "      <td>0.393264</td>\n",
       "      <td>0.804613</td>\n",
       "      <td>0.320052</td>\n",
       "      <td>0.560405</td>\n",
       "      <td>0.308584</td>\n",
       "      <td>0.398007</td>\n",
       "      <td>0.803986</td>\n",
       "      <td>0.323250</td>\n",
       "      <td>0.561580</td>\n",
       "      <td>0.308645</td>\n",
       "      <td>0.398354</td>\n",
       "      <td>0.804066</td>\n",
       "      <td>0.323930</td>\n",
       "      <td>0.561768</td>\n",
       "      <td>0.308645</td>\n",
       "      <td>0.398401</td>\n",
       "      <td>0.804091</td>\n",
       "      <td>0.324033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.441700</td>\n",
       "      <td>0.425902</td>\n",
       "      <td>0.562556</td>\n",
       "      <td>0.308216</td>\n",
       "      <td>0.398241</td>\n",
       "      <td>0.802660</td>\n",
       "      <td>0.324212</td>\n",
       "      <td>0.562267</td>\n",
       "      <td>0.305334</td>\n",
       "      <td>0.395756</td>\n",
       "      <td>0.803890</td>\n",
       "      <td>0.322362</td>\n",
       "      <td>0.561551</td>\n",
       "      <td>0.303740</td>\n",
       "      <td>0.394238</td>\n",
       "      <td>0.804031</td>\n",
       "      <td>0.321034</td>\n",
       "      <td>0.563186</td>\n",
       "      <td>0.298651</td>\n",
       "      <td>0.390320</td>\n",
       "      <td>0.804343</td>\n",
       "      <td>0.318910</td>\n",
       "      <td>0.562521</td>\n",
       "      <td>0.306438</td>\n",
       "      <td>0.396745</td>\n",
       "      <td>0.803910</td>\n",
       "      <td>0.323149</td>\n",
       "      <td>0.562309</td>\n",
       "      <td>0.304047</td>\n",
       "      <td>0.394683</td>\n",
       "      <td>0.804116</td>\n",
       "      <td>0.321626</td>\n",
       "      <td>0.563232</td>\n",
       "      <td>0.300920</td>\n",
       "      <td>0.392263</td>\n",
       "      <td>0.804395</td>\n",
       "      <td>0.320279</td>\n",
       "      <td>0.563469</td>\n",
       "      <td>0.307541</td>\n",
       "      <td>0.397906</td>\n",
       "      <td>0.803773</td>\n",
       "      <td>0.324315</td>\n",
       "      <td>0.563463</td>\n",
       "      <td>0.307296</td>\n",
       "      <td>0.397699</td>\n",
       "      <td>0.803853</td>\n",
       "      <td>0.324167</td>\n",
       "      <td>0.563497</td>\n",
       "      <td>0.307419</td>\n",
       "      <td>0.397810</td>\n",
       "      <td>0.803878</td>\n",
       "      <td>0.324258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.440200</td>\n",
       "      <td>0.425976</td>\n",
       "      <td>0.560827</td>\n",
       "      <td>0.309503</td>\n",
       "      <td>0.398878</td>\n",
       "      <td>0.802730</td>\n",
       "      <td>0.324019</td>\n",
       "      <td>0.561126</td>\n",
       "      <td>0.306744</td>\n",
       "      <td>0.396654</td>\n",
       "      <td>0.803958</td>\n",
       "      <td>0.322567</td>\n",
       "      <td>0.560987</td>\n",
       "      <td>0.305395</td>\n",
       "      <td>0.395490</td>\n",
       "      <td>0.804098</td>\n",
       "      <td>0.321700</td>\n",
       "      <td>0.561918</td>\n",
       "      <td>0.299632</td>\n",
       "      <td>0.390851</td>\n",
       "      <td>0.804406</td>\n",
       "      <td>0.318808</td>\n",
       "      <td>0.561612</td>\n",
       "      <td>0.307664</td>\n",
       "      <td>0.397544</td>\n",
       "      <td>0.803977</td>\n",
       "      <td>0.323372</td>\n",
       "      <td>0.561226</td>\n",
       "      <td>0.305457</td>\n",
       "      <td>0.395601</td>\n",
       "      <td>0.804183</td>\n",
       "      <td>0.321866</td>\n",
       "      <td>0.562151</td>\n",
       "      <td>0.302514</td>\n",
       "      <td>0.393351</td>\n",
       "      <td>0.804460</td>\n",
       "      <td>0.320637</td>\n",
       "      <td>0.562744</td>\n",
       "      <td>0.308768</td>\n",
       "      <td>0.398749</td>\n",
       "      <td>0.803841</td>\n",
       "      <td>0.324639</td>\n",
       "      <td>0.562437</td>\n",
       "      <td>0.308461</td>\n",
       "      <td>0.398416</td>\n",
       "      <td>0.803921</td>\n",
       "      <td>0.324291</td>\n",
       "      <td>0.562514</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.398384</td>\n",
       "      <td>0.803946</td>\n",
       "      <td>0.324297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 176\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT/Checkpoints/checkpoint-1569\n",
      "Configuration saved in ./Models/DR-BERT/Checkpoints/checkpoint-1569/config.json\n",
      "Model weights saved in ./Models/DR-BERT/Checkpoints/checkpoint-1569/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 176\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT/Checkpoints/checkpoint-3138\n",
      "Configuration saved in ./Models/DR-BERT/Checkpoints/checkpoint-3138/config.json\n",
      "Model weights saved in ./Models/DR-BERT/Checkpoints/checkpoint-3138/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 176\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT/Checkpoints/checkpoint-4707\n",
      "Configuration saved in ./Models/DR-BERT/Checkpoints/checkpoint-4707/config.json\n",
      "Model weights saved in ./Models/DR-BERT/Checkpoints/checkpoint-4707/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 176\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT/Checkpoints/checkpoint-6276\n",
      "Configuration saved in ./Models/DR-BERT/Checkpoints/checkpoint-6276/config.json\n",
      "Model weights saved in ./Models/DR-BERT/Checkpoints/checkpoint-6276/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 176\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT/Checkpoints/checkpoint-7845\n",
      "Configuration saved in ./Models/DR-BERT/Checkpoints/checkpoint-7845/config.json\n",
      "Model weights saved in ./Models/DR-BERT/Checkpoints/checkpoint-7845/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 176\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT/Checkpoints/checkpoint-9414\n",
      "Configuration saved in ./Models/DR-BERT/Checkpoints/checkpoint-9414/config.json\n",
      "Model weights saved in ./Models/DR-BERT/Checkpoints/checkpoint-9414/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 176\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT/Checkpoints/checkpoint-10983\n",
      "Configuration saved in ./Models/DR-BERT/Checkpoints/checkpoint-10983/config.json\n",
      "Model weights saved in ./Models/DR-BERT/Checkpoints/checkpoint-10983/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 176\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT/Checkpoints/checkpoint-12552\n",
      "Configuration saved in ./Models/DR-BERT/Checkpoints/checkpoint-12552/config.json\n",
      "Model weights saved in ./Models/DR-BERT/Checkpoints/checkpoint-12552/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 176\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT/Checkpoints/checkpoint-14121\n",
      "Configuration saved in ./Models/DR-BERT/Checkpoints/checkpoint-14121/config.json\n",
      "Model weights saved in ./Models/DR-BERT/Checkpoints/checkpoint-14121/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 176\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT/Checkpoints/checkpoint-15690\n",
      "Configuration saved in ./Models/DR-BERT/Checkpoints/checkpoint-15690/config.json\n",
      "Model weights saved in ./Models/DR-BERT/Checkpoints/checkpoint-15690/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./Models/DR-BERT/Checkpoints/checkpoint-3138 (score: 0.40570268034935).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15690, training_loss=0.4565909267155664, metrics={'train_runtime': 1112.4017, 'train_samples_per_second': 14.105, 'train_steps_per_second': 14.105, 'total_flos': 4099894279004160.0, 'train_loss': 0.4565909267155664, 'epoch': 10.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "52bb58a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([10, 1, 2, 1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "49291fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 2, 1024])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "73e48ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = nn.Conv2d(1, 1, (1,7), padding=(0,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "be0f5789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 2, 1024])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16f8beae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/johnmf4/.conda/envs/ProteinTransformers3:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_pytorch_select           2.0                  cuda10.2_1    file:///opt/apps/open-ce-v1.2.0/condabuild\r\n",
      "pytorch                   1.7.1           cuda10.2_py37_3    file:///opt/apps/open-ce-v1.2.0/condabuild\r\n",
      "pytorch-base              1.7.1           cuda10.2_py37_14    file:///opt/apps/open-ce-v1.2.0/condabuild\r\n",
      "torchtext                 0.8.1                    py37_4    file:///opt/apps/open-ce-v1.2.0/condabuild\r\n",
      "torchvision-base          0.8.2           cuda10.2_py37_6    file:///opt/apps/open-ce-v1.2.0/condabuild\r\n"
     ]
    }
   ],
   "source": [
    "!conda list torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463578e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-84b0c0af05be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb4c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ProteinTransformers3]",
   "language": "python",
   "name": "conda-env-.conda-ProteinTransformers3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
