{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d0e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizerFast, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, log_loss, accuracy_score, matthews_corrcoef\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8058986",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 1024\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-6\n",
    "BATCH_SIZE = 1\n",
    "TOKENIZER_PATH =  \"./Models/ST-PRoBERTa/Tokenizer\"\n",
    "PRETRAINED_MODEL = \"./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000\"\n",
    "NUM_CLASSES = 2\n",
    "SCHEDULER='cosine_with_restarts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5635e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pickle.load(open('./Datasets/caid_clustered_train.pkl', \"rb\"))\n",
    "df_val = pickle.load(open('./Datasets/finetuning-IDRs-test.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1601161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna()\n",
    "df_train = df_train.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8963357b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>full</th>\n",
       "      <th>disprot_ID</th>\n",
       "      <th>intersect</th>\n",
       "      <th>remove_clustered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MELITNELLYKTYKQKPVGVEEPVYDQAGDPLFGERGAVHPQSTLK...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP00675</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MEDINFASLAPRHGSRPFMGNWQDIGTSNMSGGAFSWGSLWSGIKN...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP00808</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MVSSVLSIPPQTCLLPRLPISDSVNCKSKIVYCLSTSVRGSSVKRQ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP02919</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MAAKFEVGSVYTGKVTGLQAYGAFVALDEETQGLVHISEVTHGFVK...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP00809</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VVYTDCTESGQNLCLCEGSNVCGQGNKCILGSDGEKNQCVTGEGTP...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP00137</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>MGHNDSVETMDEISNPNNILLPHDGTGLDATGISGSQEPYGMVDVL...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>DP00036</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>MLALLCSCLLLAAGASDAWTGEDSAEPNSDSAEWIRDMYAKVTEIW...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP02656</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>MGEAEKFHYIYSCDLDINVQLKIGSLEGKREQKSYKAVLEDPMLKF...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP03710</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>MASMRESDTGLWLHNKLGATDELWAPPSIASLLTAAVIDNIRLCFH...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP02712</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>MLSTQFNRDNQYQAITKPSLLAGCIALALLPSAAFAAPATEETVIV...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP03193</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1721 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sequence  \\\n",
       "0     MELITNELLYKTYKQKPVGVEEPVYDQAGDPLFGERGAVHPQSTLK...   \n",
       "5     MEDINFASLAPRHGSRPFMGNWQDIGTSNMSGGAFSWGSLWSGIKN...   \n",
       "6     MVSSVLSIPPQTCLLPRLPISDSVNCKSKIVYCLSTSVRGSSVKRQ...   \n",
       "7     MAAKFEVGSVYTGKVTGLQAYGAFVALDEETQGLVHISEVTHGFVK...   \n",
       "9     VVYTDCTESGQNLCLCEGSNVCGQGNKCILGSDGEKNQCVTGEGTP...   \n",
       "...                                                 ...   \n",
       "2380  MGHNDSVETMDEISNPNNILLPHDGTGLDATGISGSQEPYGMVDVL...   \n",
       "2381  MLALLCSCLLLAAGASDAWTGEDSAEPNSDSAEWIRDMYAKVTEIW...   \n",
       "2382  MGEAEKFHYIYSCDLDINVQLKIGSLEGKREQKSYKAVLEDPMLKF...   \n",
       "2383  MASMRESDTGLWLHNKLGATDELWAPPSIASLLTAAVIDNIRLCFH...   \n",
       "2384  MLSTQFNRDNQYQAITKPSLLAGCIALALLPSAAFAAPATEETVIV...   \n",
       "\n",
       "                                                   full disprot_ID  intersect  \\\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00675      False   \n",
       "5     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00808      False   \n",
       "6     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02919      False   \n",
       "7     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00809      False   \n",
       "9     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00137      False   \n",
       "...                                                 ...        ...        ...   \n",
       "2380  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...    DP00036      False   \n",
       "2381  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02656      False   \n",
       "2382  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP03710      False   \n",
       "2383  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02712      False   \n",
       "2384  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP03193      False   \n",
       "\n",
       "      remove_clustered  \n",
       "0                False  \n",
       "5                False  \n",
       "6                False  \n",
       "7                False  \n",
       "9                False  \n",
       "...                ...  \n",
       "2380             False  \n",
       "2381             False  \n",
       "2382             False  \n",
       "2383             False  \n",
       "2384             False  \n",
       "\n",
       "[1721 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53e8f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caid = pickle.load(open('./Datasets/caid.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fe6f82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DP00084</td>\n",
       "      <td>MSDNDDIEVESDEEQPRFQSAADKRAHHNALERKRRDHIKDSFHSL...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DP00182</td>\n",
       "      <td>MAPTKRKGSCPGAAPKKPKEPVQVPKLVIKGGIEVLGVKTGVDSFT...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DP00206</td>\n",
       "      <td>MKAAQKGFTLIELMIVVAIIGILAAIAIPAYQDYTARAQLSERMTL...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DP00334</td>\n",
       "      <td>MCNTNMSVPTDGAVTTSQIPASEQETLVRPKPLLLKLLKSVGAQKD...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DP00359</td>\n",
       "      <td>MMLTKSVVISRPAVRPVSTRRAVVVRASGQPAVDLNKKVQDAVKEA...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>DP02330</td>\n",
       "      <td>MWLPLTVLLLAGIVSADYDHGWHVNNEYIYLVRSRTLVNLNELSDQ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>DP02331</td>\n",
       "      <td>MWCPLFLVLLAGAATAEHLQAWKTDTEYQYAVRGRTLSALHDVADQ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>DP02332</td>\n",
       "      <td>MAGELADKKDRDASPSKEERKRSRTPDRERDRDRDRKSSPSKDRKR...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>DP02333</td>\n",
       "      <td>MSHIQIPPGLTELLQGYTVEVLRQQPPDLVEFAVEYFTRLREARAP...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>DP02334</td>\n",
       "      <td>MAPPGMRLRSGRSTGAPLTRGSCRKRNRSPERCDLGDDLHLQPRRK...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>652 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                           Sequence  \\\n",
       "0    DP00084  MSDNDDIEVESDEEQPRFQSAADKRAHHNALERKRRDHIKDSFHSL...   \n",
       "1    DP00182  MAPTKRKGSCPGAAPKKPKEPVQVPKLVIKGGIEVLGVKTGVDSFT...   \n",
       "2    DP00206  MKAAQKGFTLIELMIVVAIIGILAAIAIPAYQDYTARAQLSERMTL...   \n",
       "3    DP00334  MCNTNMSVPTDGAVTTSQIPASEQETLVRPKPLLLKLLKSVGAQKD...   \n",
       "4    DP00359  MMLTKSVVISRPAVRPVSTRRAVVVRASGQPAVDLNKKVQDAVKEA...   \n",
       "..       ...                                                ...   \n",
       "647  DP02330  MWLPLTVLLLAGIVSADYDHGWHVNNEYIYLVRSRTLVNLNELSDQ...   \n",
       "648  DP02331  MWCPLFLVLLAGAATAEHLQAWKTDTEYQYAVRGRTLSALHDVADQ...   \n",
       "649  DP02332  MAGELADKKDRDASPSKEERKRSRTPDRERDRDRDRKSSPSKDRKR...   \n",
       "650  DP02333  MSHIQIPPGLTELLQGYTVEVLRQQPPDLVEFAVEYFTRLREARAP...   \n",
       "651  DP02334  MAPPGMRLRSGRSTGAPLTRGSCRKRNRSPERCDLGDDLHLQPRRK...   \n",
       "\n",
       "                                                  full  \n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "..                                                 ...  \n",
       "647  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "648  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "649  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "650  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "651  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[652 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_caid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e2ab4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>full</th>\n",
       "      <th>disprot_ID</th>\n",
       "      <th>remove_clustered</th>\n",
       "      <th>intersect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MELITNELLYKTYKQKPVGVEEPVYDQAGDPLFGERGAVHPQSTLK...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP00675</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MEDINFASLAPRHGSRPFMGNWQDIGTSNMSGGAFSWGSLWSGIKN...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP00808</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MVSSVLSIPPQTCLLPRLPISDSVNCKSKIVYCLSTSVRGSSVKRQ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP02919</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MAAKFEVGSVYTGKVTGLQAYGAFVALDEETQGLVHISEVTHGFVK...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP00809</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VVYTDCTESGQNLCLCEGSNVCGQGNKCILGSDGEKNQCVTGEGTP...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP00137</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>MGHNDSVETMDEISNPNNILLPHDGTGLDATGISGSQEPYGMVDVL...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>DP00036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>MLALLCSCLLLAAGASDAWTGEDSAEPNSDSAEWIRDMYAKVTEIW...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP02656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>MGEAEKFHYIYSCDLDINVQLKIGSLEGKREQKSYKAVLEDPMLKF...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP03710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>MASMRESDTGLWLHNKLGATDELWAPPSIASLLTAAVIDNIRLCFH...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP02712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>MLSTQFNRDNQYQAITKPSLLAGCIALALLPSAAFAAPATEETVIV...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>DP03193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1723 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sequence  \\\n",
       "0    MELITNELLYKTYKQKPVGVEEPVYDQAGDPLFGERGAVHPQSTLK...   \n",
       "5    MEDINFASLAPRHGSRPFMGNWQDIGTSNMSGGAFSWGSLWSGIKN...   \n",
       "6    MVSSVLSIPPQTCLLPRLPISDSVNCKSKIVYCLSTSVRGSSVKRQ...   \n",
       "7    MAAKFEVGSVYTGKVTGLQAYGAFVALDEETQGLVHISEVTHGFVK...   \n",
       "9    VVYTDCTESGQNLCLCEGSNVCGQGNKCILGSDGEKNQCVTGEGTP...   \n",
       "..                                                 ...   \n",
       "234  MGHNDSVETMDEISNPNNILLPHDGTGLDATGISGSQEPYGMVDVL...   \n",
       "235  MLALLCSCLLLAAGASDAWTGEDSAEPNSDSAEWIRDMYAKVTEIW...   \n",
       "236  MGEAEKFHYIYSCDLDINVQLKIGSLEGKREQKSYKAVLEDPMLKF...   \n",
       "237  MASMRESDTGLWLHNKLGATDELWAPPSIASLLTAAVIDNIRLCFH...   \n",
       "238  MLSTQFNRDNQYQAITKPSLLAGCIALALLPSAAFAAPATEETVIV...   \n",
       "\n",
       "                                                  full disprot_ID  \\\n",
       "0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00675   \n",
       "5    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00808   \n",
       "6    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02919   \n",
       "7    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00809   \n",
       "9    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00137   \n",
       "..                                                 ...        ...   \n",
       "234  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...    DP00036   \n",
       "235  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02656   \n",
       "236  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP03710   \n",
       "237  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02712   \n",
       "238  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP03193   \n",
       "\n",
       "    remove_clustered  intersect  \n",
       "0              False      False  \n",
       "5              False      False  \n",
       "6              False      False  \n",
       "7              False      False  \n",
       "9              False      False  \n",
       "..               ...        ...  \n",
       "234              NaN      False  \n",
       "235              NaN      False  \n",
       "236              NaN      False  \n",
       "237              NaN      False  \n",
       "238              NaN      False  \n",
       "\n",
       "[1723 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train = df_full[~df_full['disprot_ID'].isin(df_caid['ID'])]\n",
    "df_full['intersect'] = [i in list(df_caid['ID']) for i in df_full['disprot_ID']]\n",
    "df_train = df_full[df_full['intersect'] == False]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09e3d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['full'] = [[int(i) for i in j] for j in df_train['full']]\n",
    "# df_caid['full'] = [[int(i) for i in j] for j in df_caid['full']]\n",
    "# print(df_train), print(df_caid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a46fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['disordered_content'] = [list(i).count(1)/len(i) for i in df_train['full']]\n",
    "# df_caid['disordered_content'] = [list(i).count(1)/len(i) for i in df_caid['full']]\n",
    "# df_train.hist('disordered_content')\n",
    "# df_caid.hist('disordered_content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10e5ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train[df_train['disordered_content'] < 0.9]\n",
    "# df_train.hist('disordered_content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76cb2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_train.sample(frac=0.1)\n",
    "df_train = df_train.drop(df_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0e4149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.to_pickle('val_clustered_caid.pkl')\n",
    "df_train.to_pickle('train_clustered_caid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35c1389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_caid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1806d860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          ID                                           Sequence  \\\n",
       " 0    DP00084  MSDNDDIEVESDEEQPRFQSAADKRAHHNALERKRRDHIKDSFHSL...   \n",
       " 1    DP00182  MAPTKRKGSCPGAAPKKPKEPVQVPKLVIKGGIEVLGVKTGVDSFT...   \n",
       " 2    DP00206  MKAAQKGFTLIELMIVVAIIGILAAIAIPAYQDYTARAQLSERMTL...   \n",
       " 3    DP00334  MCNTNMSVPTDGAVTTSQIPASEQETLVRPKPLLLKLLKSVGAQKD...   \n",
       " 4    DP00359  MMLTKSVVISRPAVRPVSTRRAVVVRASGQPAVDLNKKVQDAVKEA...   \n",
       " ..       ...                                                ...   \n",
       " 647  DP02330  MWLPLTVLLLAGIVSADYDHGWHVNNEYIYLVRSRTLVNLNELSDQ...   \n",
       " 648  DP02331  MWCPLFLVLLAGAATAEHLQAWKTDTEYQYAVRGRTLSALHDVADQ...   \n",
       " 649  DP02332  MAGELADKKDRDASPSKEERKRSRTPDRERDRDRDRKSSPSKDRKR...   \n",
       " 650  DP02333  MSHIQIPPGLTELLQGYTVEVLRQQPPDLVEFAVEYFTRLREARAP...   \n",
       " 651  DP02334  MAPPGMRLRSGRSTGAPLTRGSCRKRNRSPERCDLGDDLHLQPRRK...   \n",
       " \n",
       "                                                   full  \n",
       " 0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " 1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       " 2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " 3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " 4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " ..                                                 ...  \n",
       " 647  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " 648  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " 649  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       " 650  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " 651  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       " \n",
       " [652 rows x 3 columns],\n",
       "                                               Sequence  \\\n",
       " 0    MELITNELLYKTYKQKPVGVEEPVYDQAGDPLFGERGAVHPQSTLK...   \n",
       " 5    MEDINFASLAPRHGSRPFMGNWQDIGTSNMSGGAFSWGSLWSGIKN...   \n",
       " 7    MAAKFEVGSVYTGKVTGLQAYGAFVALDEETQGLVHISEVTHGFVK...   \n",
       " 9    VVYTDCTESGQNLCLCEGSNVCGQGNKCILGSDGEKNQCVTGEGTP...   \n",
       " 11   MNYIPTQTFYGRRWRPRPAARPWPLQATPVAPVVPDFQAQQMQQLI...   \n",
       " ..                                                 ...   \n",
       " 232  MITKVDRNAVRKKRHARIRKKIFGTTERPRLSVFRSNKHIYAQIID...   \n",
       " 234  MGHNDSVETMDEISNPNNILLPHDGTGLDATGISGSQEPYGMVDVL...   \n",
       " 235  MLALLCSCLLLAAGASDAWTGEDSAEPNSDSAEWIRDMYAKVTEIW...   \n",
       " 236  MGEAEKFHYIYSCDLDINVQLKIGSLEGKREQKSYKAVLEDPMLKF...   \n",
       " 238  MLSTQFNRDNQYQAITKPSLLAGCIALALLPSAAFAAPATEETVIV...   \n",
       " \n",
       "                                                   full disprot_ID  intersect  \n",
       " 0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00675      False  \n",
       " 5    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00808      False  \n",
       " 7    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00809      False  \n",
       " 9    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00137      False  \n",
       " 11   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00999      False  \n",
       " ..                                                 ...        ...        ...  \n",
       " 232  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...    DP00966      False  \n",
       " 234  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...    DP00036      False  \n",
       " 235  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02656      False  \n",
       " 236  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP03710      False  \n",
       " 238  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP03193      False  \n",
       " \n",
       " [1569 rows x 4 columns],\n",
       "                                                Sequence  \\\n",
       " 1823  MIPVTILCVLLCLNLAWAQDGKTTFEKEGGGGRGPRILENMHESSC...   \n",
       " 1283  MGNLESTDGGPGEPPSVPLLLPPGKTPMPEPCELEERFALVLSSMN...   \n",
       " 1868  MSGSVSGCGSGGCSIVWFRRDLRVEDNPALAAAVRAGPVIALFVWA...   \n",
       " 1416  MATVNQLVRKPRARKVAKSNVPALEACPQKRGVCTRVYTTTPKKPN...   \n",
       " 170   MAQWEMLQNLDSPFQDQLHQLYSHSLLPVDIRQYLAVWIEDQNWQE...   \n",
       " ...                                                 ...   \n",
       " 1154  MFGCLVAGRLVQTAAQQVAEDKFVFDLPDYESINHVVVFMLGTIPF...   \n",
       " 1446  MKYRYFAKKSFLFISMLAAFKTFAFELPSVPFPAPGSDEILFVVRD...   \n",
       " 2033  MQVEANSERRVKILGIDRSENSPVLTYMETEDDPNFRNSKLAAAPH...   \n",
       " 950   MLNRENKTAITRKGMVSNRLNKFSIRKYTVGTASILVGTTLIFGLG...   \n",
       " 1762  MKTLADALKEFEVLSFEIDEQALAFDVDNIEMVIEKSDITPVPKSR...   \n",
       " \n",
       "                                                    full disprot_ID  intersect  \n",
       " 1823  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00233      False  \n",
       " 1283  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02638      False  \n",
       " 1868  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...    DP00474      False  \n",
       " 1416  [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...    DP00145      False  \n",
       " 170   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00961      False  \n",
       " ...                                                 ...        ...        ...  \n",
       " 1154  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP02719      False  \n",
       " 1446  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00668      False  \n",
       " 2033  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP03107      False  \n",
       " 950   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00065      False  \n",
       " 1762  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    DP00350      False  \n",
       " \n",
       " [176 rows x 4 columns])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test, df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0a7edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDegreeDataset(Dataset):\n",
    "\n",
    "    def __init__(self, max_length, df, tokenizer, region_type):\n",
    "        self.region_type = region_type\n",
    "        self.df = df\n",
    "        self.seqs, self.labels = self.load_dataset()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def load_dataset(self):\n",
    "        seq = list(self.df['Sequence'])\n",
    "        label = list(self.df[self.region_type])\n",
    "        return seq, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        seq = \" \".join(\"\".join(self.seqs[idx].split()))\n",
    "        seq = re.sub(r\"[UZOB]\", \"X\", seq)\n",
    "\n",
    "        seq_ids = self.tokenizer(seq, truncation=True, padding='max_length', max_length=self.max_length)\n",
    "        sample = {key: torch.tensor(val) for key, val in seq_ids.items()}\n",
    "        tens = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        sample['labels'] = F.pad(tens, (0, MAX_LENGTH - len(tens)))\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b6911f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ./Models/ST-PRoBERTa/Tokenizer/tokenizer.json. We won't load it.\n",
      "Didn't find file ./Models/ST-PRoBERTa/Tokenizer/added_tokens.json. We won't load it.\n",
      "Didn't find file ./Models/ST-PRoBERTa/Tokenizer/tokenizer_config.json. We won't load it.\n",
      "loading file ./Models/ST-PRoBERTa/Tokenizer/vocab.json\n",
      "loading file ./Models/ST-PRoBERTa/Tokenizer/merges.txt\n",
      "loading file None\n",
      "loading file None\n",
      "loading file ./Models/ST-PRoBERTa/Tokenizer/special_tokens_map.json\n",
      "loading file None\n",
      "file ./Models/ST-PRoBERTa/Tokenizer/config.json not found\n",
      "Adding [SEP] to the vocabulary\n",
      "Adding [PAD] to the vocabulary\n",
      "Adding [CLS] to the vocabulary\n",
      "Adding [MASK] to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "file ./Models/ST-PRoBERTa/Tokenizer/config.json not found\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(TOKENIZER_PATH, do_lower_case=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10fc1436",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ProteinDegreeDataset(MAX_LENGTH, df_train, tokenizer, 'full')\n",
    "val_dataset = ProteinDegreeDataset(MAX_LENGTH, df_val, tokenizer, 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e39540f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = f'./Models/DR-BERT-caid-clustered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fdf4a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0009a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_f1_roc_convolve(name, logits, labels, convolution):\n",
    "    convolved = np.convolve(np.array(logits).flatten(), np.array(convolution / np.sum(convolution)).flatten(), 'same')\n",
    "    p = [(1 - i, i) for i in convolved]\n",
    "    roc = [i[1] for i in p]\n",
    "    roc2 = [i[0] for i in p]\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(labels, p)\n",
    "    roc_auc = roc_auc_score(labels, roc)\n",
    "    mcc = matthews_corrcoef(labels, p)\n",
    "    return {\n",
    "        f'precision_{name}':precision[1],\n",
    "        f'recall_{name}':recall[1],\n",
    "        f'f1_{name}':f1[1],\n",
    "        f'roc_auc_{name}':roc_auc,\n",
    "        f'mcc_{name}': mcc,\n",
    "    }\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    logits = softmax(logits, axis=2)\n",
    "    l = []\n",
    "    for j, i in enumerate(labels):\n",
    "        l = l + list(i[:len(df_val['Sequence'].iloc[j])])\n",
    "    lg2 = []\n",
    "    for k, i in enumerate(logits):\n",
    "        lg2 = lg2 + [j[1] for j in i[:len(df_val['Sequence'].iloc[k])]]\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics.update(precision_recall_f1_roc_convolve('normal', lg2, l, [1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('wa5', lg2, l, [1,1,1,1,1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('wa9', lg2, l, [1,1,1,1,1,1,1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('wa15', lg2, l, [1]*15))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('linear5', lg2, l, [1,2,3,2,1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('linear9', lg2, l, [1,2,3,4,5,4,3,2,1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('linear15', lg2, l, [1,2,3,4,5,6,7,8,7,6,5,4,3,2,1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('quad5', lg2, l, [1,3,9,3,1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('quad9', lg2, l, [1,3,9,27,81,27,9,3,1]))\n",
    "    metrics.update(precision_recall_f1_roc_convolve('quad15', lg2, l, [1,3,9,27,81,243,729,2187,729,243,81,27,9,3,1]))\n",
    "    \n",
    "    logits_path = OUTPUT_DIR + '/Logits/'\n",
    "    if not os.path.isdir(logits_path):\n",
    "        os.mkdir(logits_path)\n",
    "    new_df = deepcopy(df_val)\n",
    "    new_df['Logits'] = [[i[1] for i in x] for x in list(logits)]\n",
    "    pickle.dump(new_df, open(logits_path + datetime.now().strftime(\"%H:%M:%S\"), 'wb'))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "882d3738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = OUTPUT_DIR + '/Checkpoints',\n",
    "    num_train_epochs = EPOCHS,\n",
    "    per_device_train_batch_size = 1,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    warmup_steps = 1000,\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    logging_dir = OUTPUT_DIR + '/Logs',\n",
    "    logging_steps = 200,\n",
    "    lr_scheduler_type=SCHEDULER,\n",
    "    do_train = True,\n",
    "    do_eval = True,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    gradient_accumulation_steps = BATCH_SIZE,\n",
    "    fp16 = True,\n",
    "    fp16_opt_level = '02',\n",
    "    save_strategy = 'epoch',\n",
    "    load_best_model_at_end = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5d3121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "def model_init():\n",
    "    model = AutoModelForTokenClassification.from_pretrained(PRETRAINED_MODEL, num_labels=NUM_CLASSES)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27db5718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 35\n",
      "}\n",
      "\n",
      "loading weights file ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000/pytorch_model.bin\n",
      "Some weights of the model checkpoint at ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000 were not used when initializing RobertaForTokenClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = val_dataset,\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3af3900e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 35\n",
      "}\n",
      "\n",
      "loading weights file ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000/pytorch_model.bin\n",
      "Some weights of the model checkpoint at ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000 were not used when initializing RobertaForTokenClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at ./Models/ST-PRoBERTa/Checkpoints/checkpoint-3560000 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/johnmf4/.conda/envs/ProteinTransformers3/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1721\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17210\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17210' max='17210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17210/17210 20:22, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision Normal</th>\n",
       "      <th>Recall Normal</th>\n",
       "      <th>F1 Normal</th>\n",
       "      <th>Roc Auc Normal</th>\n",
       "      <th>Mcc Normal</th>\n",
       "      <th>Precision Wa5</th>\n",
       "      <th>Recall Wa5</th>\n",
       "      <th>F1 Wa5</th>\n",
       "      <th>Roc Auc Wa5</th>\n",
       "      <th>Mcc Wa5</th>\n",
       "      <th>Precision Wa9</th>\n",
       "      <th>Recall Wa9</th>\n",
       "      <th>F1 Wa9</th>\n",
       "      <th>Roc Auc Wa9</th>\n",
       "      <th>Mcc Wa9</th>\n",
       "      <th>Precision Wa15</th>\n",
       "      <th>Recall Wa15</th>\n",
       "      <th>F1 Wa15</th>\n",
       "      <th>Roc Auc Wa15</th>\n",
       "      <th>Mcc Wa15</th>\n",
       "      <th>Precision Linear5</th>\n",
       "      <th>Recall Linear5</th>\n",
       "      <th>F1 Linear5</th>\n",
       "      <th>Roc Auc Linear5</th>\n",
       "      <th>Mcc Linear5</th>\n",
       "      <th>Precision Linear9</th>\n",
       "      <th>Recall Linear9</th>\n",
       "      <th>F1 Linear9</th>\n",
       "      <th>Roc Auc Linear9</th>\n",
       "      <th>Mcc Linear9</th>\n",
       "      <th>Precision Linear15</th>\n",
       "      <th>Recall Linear15</th>\n",
       "      <th>F1 Linear15</th>\n",
       "      <th>Roc Auc Linear15</th>\n",
       "      <th>Mcc Linear15</th>\n",
       "      <th>Precision Quad5</th>\n",
       "      <th>Recall Quad5</th>\n",
       "      <th>F1 Quad5</th>\n",
       "      <th>Roc Auc Quad5</th>\n",
       "      <th>Mcc Quad5</th>\n",
       "      <th>Precision Quad9</th>\n",
       "      <th>Recall Quad9</th>\n",
       "      <th>F1 Quad9</th>\n",
       "      <th>Roc Auc Quad9</th>\n",
       "      <th>Mcc Quad9</th>\n",
       "      <th>Precision Quad15</th>\n",
       "      <th>Recall Quad15</th>\n",
       "      <th>F1 Quad15</th>\n",
       "      <th>Roc Auc Quad15</th>\n",
       "      <th>Mcc Quad15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.521700</td>\n",
       "      <td>0.421316</td>\n",
       "      <td>0.830161</td>\n",
       "      <td>0.029482</td>\n",
       "      <td>0.056942</td>\n",
       "      <td>0.764981</td>\n",
       "      <td>0.134376</td>\n",
       "      <td>0.785888</td>\n",
       "      <td>0.016795</td>\n",
       "      <td>0.032887</td>\n",
       "      <td>0.769420</td>\n",
       "      <td>0.096888</td>\n",
       "      <td>0.774359</td>\n",
       "      <td>0.015703</td>\n",
       "      <td>0.030782</td>\n",
       "      <td>0.769740</td>\n",
       "      <td>0.092541</td>\n",
       "      <td>0.774373</td>\n",
       "      <td>0.014455</td>\n",
       "      <td>0.028380</td>\n",
       "      <td>0.769922</td>\n",
       "      <td>0.088776</td>\n",
       "      <td>0.793981</td>\n",
       "      <td>0.017835</td>\n",
       "      <td>0.034886</td>\n",
       "      <td>0.769292</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.778351</td>\n",
       "      <td>0.015703</td>\n",
       "      <td>0.030785</td>\n",
       "      <td>0.769854</td>\n",
       "      <td>0.092934</td>\n",
       "      <td>0.772118</td>\n",
       "      <td>0.014975</td>\n",
       "      <td>0.029380</td>\n",
       "      <td>0.770097</td>\n",
       "      <td>0.090147</td>\n",
       "      <td>0.815514</td>\n",
       "      <td>0.020227</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.768649</td>\n",
       "      <td>0.109611</td>\n",
       "      <td>0.813449</td>\n",
       "      <td>0.019499</td>\n",
       "      <td>0.038085</td>\n",
       "      <td>0.768853</td>\n",
       "      <td>0.107393</td>\n",
       "      <td>0.813043</td>\n",
       "      <td>0.019447</td>\n",
       "      <td>0.037985</td>\n",
       "      <td>0.768877</td>\n",
       "      <td>0.107206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.468200</td>\n",
       "      <td>0.404651</td>\n",
       "      <td>0.559500</td>\n",
       "      <td>0.402402</td>\n",
       "      <td>0.468122</td>\n",
       "      <td>0.792719</td>\n",
       "      <td>0.374110</td>\n",
       "      <td>0.561175</td>\n",
       "      <td>0.400426</td>\n",
       "      <td>0.467365</td>\n",
       "      <td>0.794594</td>\n",
       "      <td>0.374092</td>\n",
       "      <td>0.562156</td>\n",
       "      <td>0.398087</td>\n",
       "      <td>0.466105</td>\n",
       "      <td>0.794823</td>\n",
       "      <td>0.373436</td>\n",
       "      <td>0.568177</td>\n",
       "      <td>0.389351</td>\n",
       "      <td>0.462065</td>\n",
       "      <td>0.795053</td>\n",
       "      <td>0.372373</td>\n",
       "      <td>0.560827</td>\n",
       "      <td>0.400790</td>\n",
       "      <td>0.467492</td>\n",
       "      <td>0.794546</td>\n",
       "      <td>0.374071</td>\n",
       "      <td>0.562151</td>\n",
       "      <td>0.398347</td>\n",
       "      <td>0.466281</td>\n",
       "      <td>0.794916</td>\n",
       "      <td>0.373574</td>\n",
       "      <td>0.565901</td>\n",
       "      <td>0.394707</td>\n",
       "      <td>0.465049</td>\n",
       "      <td>0.795212</td>\n",
       "      <td>0.373915</td>\n",
       "      <td>0.560875</td>\n",
       "      <td>0.401466</td>\n",
       "      <td>0.467968</td>\n",
       "      <td>0.794298</td>\n",
       "      <td>0.374466</td>\n",
       "      <td>0.561368</td>\n",
       "      <td>0.401206</td>\n",
       "      <td>0.467963</td>\n",
       "      <td>0.794426</td>\n",
       "      <td>0.374634</td>\n",
       "      <td>0.561508</td>\n",
       "      <td>0.401102</td>\n",
       "      <td>0.467941</td>\n",
       "      <td>0.794453</td>\n",
       "      <td>0.374666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.492200</td>\n",
       "      <td>0.399452</td>\n",
       "      <td>0.579419</td>\n",
       "      <td>0.436824</td>\n",
       "      <td>0.498117</td>\n",
       "      <td>0.802403</td>\n",
       "      <td>0.405286</td>\n",
       "      <td>0.582615</td>\n",
       "      <td>0.432508</td>\n",
       "      <td>0.496464</td>\n",
       "      <td>0.803912</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.583703</td>\n",
       "      <td>0.430584</td>\n",
       "      <td>0.495586</td>\n",
       "      <td>0.804126</td>\n",
       "      <td>0.404591</td>\n",
       "      <td>0.586018</td>\n",
       "      <td>0.423669</td>\n",
       "      <td>0.491791</td>\n",
       "      <td>0.804423</td>\n",
       "      <td>0.402239</td>\n",
       "      <td>0.583019</td>\n",
       "      <td>0.434536</td>\n",
       "      <td>0.497944</td>\n",
       "      <td>0.803884</td>\n",
       "      <td>0.406319</td>\n",
       "      <td>0.583216</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>0.495514</td>\n",
       "      <td>0.804213</td>\n",
       "      <td>0.404371</td>\n",
       "      <td>0.585119</td>\n",
       "      <td>0.427309</td>\n",
       "      <td>0.493915</td>\n",
       "      <td>0.804529</td>\n",
       "      <td>0.403682</td>\n",
       "      <td>0.582193</td>\n",
       "      <td>0.435888</td>\n",
       "      <td>0.498528</td>\n",
       "      <td>0.803691</td>\n",
       "      <td>0.406534</td>\n",
       "      <td>0.582515</td>\n",
       "      <td>0.435160</td>\n",
       "      <td>0.498170</td>\n",
       "      <td>0.803810</td>\n",
       "      <td>0.406341</td>\n",
       "      <td>0.582515</td>\n",
       "      <td>0.435160</td>\n",
       "      <td>0.498170</td>\n",
       "      <td>0.803837</td>\n",
       "      <td>0.406341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.455300</td>\n",
       "      <td>0.394838</td>\n",
       "      <td>0.584456</td>\n",
       "      <td>0.462562</td>\n",
       "      <td>0.516414</td>\n",
       "      <td>0.808546</td>\n",
       "      <td>0.422411</td>\n",
       "      <td>0.586147</td>\n",
       "      <td>0.458507</td>\n",
       "      <td>0.514529</td>\n",
       "      <td>0.809902</td>\n",
       "      <td>0.421317</td>\n",
       "      <td>0.585910</td>\n",
       "      <td>0.457103</td>\n",
       "      <td>0.513553</td>\n",
       "      <td>0.810093</td>\n",
       "      <td>0.420406</td>\n",
       "      <td>0.589456</td>\n",
       "      <td>0.450551</td>\n",
       "      <td>0.510727</td>\n",
       "      <td>0.810241</td>\n",
       "      <td>0.419118</td>\n",
       "      <td>0.586765</td>\n",
       "      <td>0.460119</td>\n",
       "      <td>0.515781</td>\n",
       "      <td>0.809898</td>\n",
       "      <td>0.422585</td>\n",
       "      <td>0.586830</td>\n",
       "      <td>0.457363</td>\n",
       "      <td>0.514070</td>\n",
       "      <td>0.810177</td>\n",
       "      <td>0.421138</td>\n",
       "      <td>0.587867</td>\n",
       "      <td>0.453983</td>\n",
       "      <td>0.512322</td>\n",
       "      <td>0.810426</td>\n",
       "      <td>0.419971</td>\n",
       "      <td>0.586590</td>\n",
       "      <td>0.461262</td>\n",
       "      <td>0.516431</td>\n",
       "      <td>0.809735</td>\n",
       "      <td>0.423090</td>\n",
       "      <td>0.586394</td>\n",
       "      <td>0.460743</td>\n",
       "      <td>0.516029</td>\n",
       "      <td>0.809836</td>\n",
       "      <td>0.422683</td>\n",
       "      <td>0.586522</td>\n",
       "      <td>0.460691</td>\n",
       "      <td>0.516046</td>\n",
       "      <td>0.809861</td>\n",
       "      <td>0.422737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.404200</td>\n",
       "      <td>0.392586</td>\n",
       "      <td>0.619528</td>\n",
       "      <td>0.434172</td>\n",
       "      <td>0.510547</td>\n",
       "      <td>0.810838</td>\n",
       "      <td>0.428572</td>\n",
       "      <td>0.622008</td>\n",
       "      <td>0.429700</td>\n",
       "      <td>0.508272</td>\n",
       "      <td>0.812152</td>\n",
       "      <td>0.427501</td>\n",
       "      <td>0.621769</td>\n",
       "      <td>0.427725</td>\n",
       "      <td>0.506808</td>\n",
       "      <td>0.812353</td>\n",
       "      <td>0.426226</td>\n",
       "      <td>0.621590</td>\n",
       "      <td>0.420653</td>\n",
       "      <td>0.501752</td>\n",
       "      <td>0.812575</td>\n",
       "      <td>0.422055</td>\n",
       "      <td>0.622117</td>\n",
       "      <td>0.430584</td>\n",
       "      <td>0.508927</td>\n",
       "      <td>0.812139</td>\n",
       "      <td>0.428072</td>\n",
       "      <td>0.622620</td>\n",
       "      <td>0.428505</td>\n",
       "      <td>0.507638</td>\n",
       "      <td>0.812430</td>\n",
       "      <td>0.427179</td>\n",
       "      <td>0.622400</td>\n",
       "      <td>0.424761</td>\n",
       "      <td>0.504929</td>\n",
       "      <td>0.812721</td>\n",
       "      <td>0.424898</td>\n",
       "      <td>0.621474</td>\n",
       "      <td>0.431884</td>\n",
       "      <td>0.509617</td>\n",
       "      <td>0.811985</td>\n",
       "      <td>0.428432</td>\n",
       "      <td>0.621488</td>\n",
       "      <td>0.431312</td>\n",
       "      <td>0.509224</td>\n",
       "      <td>0.812084</td>\n",
       "      <td>0.428114</td>\n",
       "      <td>0.621535</td>\n",
       "      <td>0.431312</td>\n",
       "      <td>0.509239</td>\n",
       "      <td>0.812110</td>\n",
       "      <td>0.428141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.420500</td>\n",
       "      <td>0.398888</td>\n",
       "      <td>0.597055</td>\n",
       "      <td>0.465890</td>\n",
       "      <td>0.523380</td>\n",
       "      <td>0.812101</td>\n",
       "      <td>0.432320</td>\n",
       "      <td>0.598935</td>\n",
       "      <td>0.462094</td>\n",
       "      <td>0.521691</td>\n",
       "      <td>0.813289</td>\n",
       "      <td>0.431444</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.460275</td>\n",
       "      <td>0.520537</td>\n",
       "      <td>0.813449</td>\n",
       "      <td>0.430462</td>\n",
       "      <td>0.600658</td>\n",
       "      <td>0.455335</td>\n",
       "      <td>0.517997</td>\n",
       "      <td>0.813494</td>\n",
       "      <td>0.428822</td>\n",
       "      <td>0.599219</td>\n",
       "      <td>0.462874</td>\n",
       "      <td>0.522295</td>\n",
       "      <td>0.813292</td>\n",
       "      <td>0.432052</td>\n",
       "      <td>0.599270</td>\n",
       "      <td>0.461106</td>\n",
       "      <td>0.521187</td>\n",
       "      <td>0.813526</td>\n",
       "      <td>0.431116</td>\n",
       "      <td>0.600299</td>\n",
       "      <td>0.458715</td>\n",
       "      <td>0.520042</td>\n",
       "      <td>0.813722</td>\n",
       "      <td>0.430455</td>\n",
       "      <td>0.597988</td>\n",
       "      <td>0.463602</td>\n",
       "      <td>0.522289</td>\n",
       "      <td>0.813163</td>\n",
       "      <td>0.431666</td>\n",
       "      <td>0.598187</td>\n",
       "      <td>0.463134</td>\n",
       "      <td>0.522068</td>\n",
       "      <td>0.813251</td>\n",
       "      <td>0.431537</td>\n",
       "      <td>0.598307</td>\n",
       "      <td>0.463134</td>\n",
       "      <td>0.522114</td>\n",
       "      <td>0.813273</td>\n",
       "      <td>0.431614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.443700</td>\n",
       "      <td>0.396255</td>\n",
       "      <td>0.593124</td>\n",
       "      <td>0.479045</td>\n",
       "      <td>0.530016</td>\n",
       "      <td>0.814013</td>\n",
       "      <td>0.436917</td>\n",
       "      <td>0.595547</td>\n",
       "      <td>0.475614</td>\n",
       "      <td>0.528866</td>\n",
       "      <td>0.815154</td>\n",
       "      <td>0.436634</td>\n",
       "      <td>0.596638</td>\n",
       "      <td>0.474314</td>\n",
       "      <td>0.528490</td>\n",
       "      <td>0.815283</td>\n",
       "      <td>0.436634</td>\n",
       "      <td>0.595573</td>\n",
       "      <td>0.467242</td>\n",
       "      <td>0.523660</td>\n",
       "      <td>0.815241</td>\n",
       "      <td>0.432107</td>\n",
       "      <td>0.595492</td>\n",
       "      <td>0.476653</td>\n",
       "      <td>0.529487</td>\n",
       "      <td>0.815167</td>\n",
       "      <td>0.437162</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>0.474782</td>\n",
       "      <td>0.528705</td>\n",
       "      <td>0.815362</td>\n",
       "      <td>0.436764</td>\n",
       "      <td>0.595334</td>\n",
       "      <td>0.470986</td>\n",
       "      <td>0.525909</td>\n",
       "      <td>0.815507</td>\n",
       "      <td>0.433988</td>\n",
       "      <td>0.595331</td>\n",
       "      <td>0.477329</td>\n",
       "      <td>0.529840</td>\n",
       "      <td>0.815047</td>\n",
       "      <td>0.437423</td>\n",
       "      <td>0.595560</td>\n",
       "      <td>0.477017</td>\n",
       "      <td>0.529738</td>\n",
       "      <td>0.815126</td>\n",
       "      <td>0.437403</td>\n",
       "      <td>0.595532</td>\n",
       "      <td>0.476809</td>\n",
       "      <td>0.529599</td>\n",
       "      <td>0.815146</td>\n",
       "      <td>0.437272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.396642</td>\n",
       "      <td>0.599552</td>\n",
       "      <td>0.473014</td>\n",
       "      <td>0.528818</td>\n",
       "      <td>0.814391</td>\n",
       "      <td>0.437802</td>\n",
       "      <td>0.601643</td>\n",
       "      <td>0.468282</td>\n",
       "      <td>0.526651</td>\n",
       "      <td>0.815532</td>\n",
       "      <td>0.436554</td>\n",
       "      <td>0.601756</td>\n",
       "      <td>0.466774</td>\n",
       "      <td>0.525739</td>\n",
       "      <td>0.815663</td>\n",
       "      <td>0.435800</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>0.461106</td>\n",
       "      <td>0.522292</td>\n",
       "      <td>0.815631</td>\n",
       "      <td>0.432970</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.469270</td>\n",
       "      <td>0.527331</td>\n",
       "      <td>0.815542</td>\n",
       "      <td>0.437187</td>\n",
       "      <td>0.601714</td>\n",
       "      <td>0.467242</td>\n",
       "      <td>0.526020</td>\n",
       "      <td>0.815740</td>\n",
       "      <td>0.436030</td>\n",
       "      <td>0.602496</td>\n",
       "      <td>0.464434</td>\n",
       "      <td>0.524532</td>\n",
       "      <td>0.815891</td>\n",
       "      <td>0.434986</td>\n",
       "      <td>0.601408</td>\n",
       "      <td>0.470882</td>\n",
       "      <td>0.528201</td>\n",
       "      <td>0.815420</td>\n",
       "      <td>0.437826</td>\n",
       "      <td>0.601437</td>\n",
       "      <td>0.469998</td>\n",
       "      <td>0.527655</td>\n",
       "      <td>0.815500</td>\n",
       "      <td>0.437362</td>\n",
       "      <td>0.601571</td>\n",
       "      <td>0.469946</td>\n",
       "      <td>0.527674</td>\n",
       "      <td>0.815521</td>\n",
       "      <td>0.437419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.409100</td>\n",
       "      <td>0.396790</td>\n",
       "      <td>0.598690</td>\n",
       "      <td>0.475354</td>\n",
       "      <td>0.529940</td>\n",
       "      <td>0.814690</td>\n",
       "      <td>0.438521</td>\n",
       "      <td>0.600239</td>\n",
       "      <td>0.470778</td>\n",
       "      <td>0.527684</td>\n",
       "      <td>0.815827</td>\n",
       "      <td>0.437022</td>\n",
       "      <td>0.600985</td>\n",
       "      <td>0.469738</td>\n",
       "      <td>0.527317</td>\n",
       "      <td>0.815955</td>\n",
       "      <td>0.436931</td>\n",
       "      <td>0.601038</td>\n",
       "      <td>0.463654</td>\n",
       "      <td>0.523482</td>\n",
       "      <td>0.815911</td>\n",
       "      <td>0.433634</td>\n",
       "      <td>0.600543</td>\n",
       "      <td>0.471922</td>\n",
       "      <td>0.528519</td>\n",
       "      <td>0.815838</td>\n",
       "      <td>0.437841</td>\n",
       "      <td>0.600798</td>\n",
       "      <td>0.469998</td>\n",
       "      <td>0.527409</td>\n",
       "      <td>0.816033</td>\n",
       "      <td>0.436954</td>\n",
       "      <td>0.600749</td>\n",
       "      <td>0.467242</td>\n",
       "      <td>0.525651</td>\n",
       "      <td>0.816178</td>\n",
       "      <td>0.435415</td>\n",
       "      <td>0.600554</td>\n",
       "      <td>0.473742</td>\n",
       "      <td>0.529663</td>\n",
       "      <td>0.815718</td>\n",
       "      <td>0.438841</td>\n",
       "      <td>0.600290</td>\n",
       "      <td>0.473222</td>\n",
       "      <td>0.529236</td>\n",
       "      <td>0.815795</td>\n",
       "      <td>0.438389</td>\n",
       "      <td>0.600330</td>\n",
       "      <td>0.473066</td>\n",
       "      <td>0.529153</td>\n",
       "      <td>0.815817</td>\n",
       "      <td>0.438329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.433800</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.598028</td>\n",
       "      <td>0.476290</td>\n",
       "      <td>0.530261</td>\n",
       "      <td>0.814678</td>\n",
       "      <td>0.438603</td>\n",
       "      <td>0.599868</td>\n",
       "      <td>0.471454</td>\n",
       "      <td>0.527965</td>\n",
       "      <td>0.815812</td>\n",
       "      <td>0.437154</td>\n",
       "      <td>0.600305</td>\n",
       "      <td>0.470518</td>\n",
       "      <td>0.527546</td>\n",
       "      <td>0.815940</td>\n",
       "      <td>0.436923</td>\n",
       "      <td>0.600471</td>\n",
       "      <td>0.464278</td>\n",
       "      <td>0.523664</td>\n",
       "      <td>0.815893</td>\n",
       "      <td>0.433616</td>\n",
       "      <td>0.600040</td>\n",
       "      <td>0.472650</td>\n",
       "      <td>0.528780</td>\n",
       "      <td>0.815823</td>\n",
       "      <td>0.437916</td>\n",
       "      <td>0.600464</td>\n",
       "      <td>0.470830</td>\n",
       "      <td>0.527804</td>\n",
       "      <td>0.816017</td>\n",
       "      <td>0.437195</td>\n",
       "      <td>0.600253</td>\n",
       "      <td>0.467918</td>\n",
       "      <td>0.525888</td>\n",
       "      <td>0.816162</td>\n",
       "      <td>0.435469</td>\n",
       "      <td>0.600092</td>\n",
       "      <td>0.474470</td>\n",
       "      <td>0.529938</td>\n",
       "      <td>0.815705</td>\n",
       "      <td>0.438942</td>\n",
       "      <td>0.599947</td>\n",
       "      <td>0.473950</td>\n",
       "      <td>0.529557</td>\n",
       "      <td>0.815783</td>\n",
       "      <td>0.438565</td>\n",
       "      <td>0.599974</td>\n",
       "      <td>0.473846</td>\n",
       "      <td>0.529502</td>\n",
       "      <td>0.815803</td>\n",
       "      <td>0.438526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 240\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-1721\n",
      "Configuration saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-1721/config.json\n",
      "Model weights saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-1721/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 240\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-3442\n",
      "Configuration saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-3442/config.json\n",
      "Model weights saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-3442/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 240\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-5163\n",
      "Configuration saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-5163/config.json\n",
      "Model weights saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-5163/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 240\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-6884\n",
      "Configuration saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-6884/config.json\n",
      "Model weights saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-6884/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 240\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-8605\n",
      "Configuration saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-8605/config.json\n",
      "Model weights saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-8605/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 240\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-10326\n",
      "Configuration saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-10326/config.json\n",
      "Model weights saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-10326/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 240\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-12047\n",
      "Configuration saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-12047/config.json\n",
      "Model weights saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-12047/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 240\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-13768\n",
      "Configuration saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-13768/config.json\n",
      "Model weights saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-13768/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 240\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-15489\n",
      "Configuration saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-15489/config.json\n",
      "Model weights saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-15489/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 240\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-17210\n",
      "Configuration saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-17210/config.json\n",
      "Model weights saved in ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-17210/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./Models/DR-BERT-caid-clustered/Checkpoints/checkpoint-8605 (score: 0.3925863802433014).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17210, training_loss=0.45348676651595016, metrics={'train_runtime': 1222.7752, 'train_samples_per_second': 14.075, 'train_steps_per_second': 14.075, 'total_flos': 4497079703101440.0, 'train_loss': 0.45348676651595016, 'epoch': 10.0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "52bb58a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([10, 1, 2, 1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "49291fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 2, 1024])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "73e48ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = nn.Conv2d(1, 1, (1,7), padding=(0,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "be0f5789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 2, 1024])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16f8beae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/johnmf4/.conda/envs/ProteinTransformers3:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_pytorch_select           2.0                  cuda10.2_1    file:///opt/apps/open-ce-v1.2.0/condabuild\r\n",
      "pytorch                   1.7.1           cuda10.2_py37_3    file:///opt/apps/open-ce-v1.2.0/condabuild\r\n",
      "pytorch-base              1.7.1           cuda10.2_py37_14    file:///opt/apps/open-ce-v1.2.0/condabuild\r\n",
      "torchtext                 0.8.1                    py37_4    file:///opt/apps/open-ce-v1.2.0/condabuild\r\n",
      "torchvision-base          0.8.2           cuda10.2_py37_6    file:///opt/apps/open-ce-v1.2.0/condabuild\r\n"
     ]
    }
   ],
   "source": [
    "!conda list torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463578e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-84b0c0af05be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb4c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ProteinTransformers3]",
   "language": "python",
   "name": "conda-env-.conda-ProteinTransformers3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
